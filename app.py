import cv2
import time
import pygame
import numpy as np
import onnxruntime as ort
from flask import Flask, render_template, Response
from flask_socketio import SocketIO

app = Flask(__name__, static_folder='static')
socketio = SocketIO(app, async_mode="threading")  # ë¹„ë™ê¸° ëª¨ë“œ ì„¤ì •

# âœ… ONNX ëª¨ë¸ ë¡œë“œ
onnx_model_path_1 = "weights/yolov11n_20250226_075134_e50b32_dataset_face_class_only/weights/best.onnx"
onnx_model_path_2 = "weights/yolov11n_20250226_01_41_20_e50b32_dataset_calling_drinking_only/weights/best.onnx"

session_1 = ort.InferenceSession(onnx_model_path_1, providers=["CUDAExecutionProvider", "CPUExecutionProvider"])
session_2 = ort.InferenceSession(onnx_model_path_2, providers=["CUDAExecutionProvider", "CPUExecutionProvider"])

# âœ… í´ë˜ìŠ¤ ì •ì˜
class_names_1 = ["Distracted", "SafeDriving", "SleepyDriving", "Yawn"]
class_names_2 = ["Calling", "Drinking"]

# âœ… pygame ì´ˆê¸°í™” ë° ì•ŒëŒ íŒŒì¼ ë¡œë“œ
pygame.mixer.init()
alarms = {
    "SleepyDriving": pygame.mixer.Sound("asset/sleepy.mp3"),
    "Distracted": pygame.mixer.Sound("asset/distract.mp3"),
    "Yawn": pygame.mixer.Sound("asset/yawn.mp3"),
    "Calling": pygame.mixer.Sound("asset/calling.mp3"),
    "Drinking": pygame.mixer.Sound("asset/drinking.mp3"),
}

# âœ… ê°ì§€ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
state_flags = {
    "Distracted": {"start_time": None, "detected": False},
    "SafeDriving": {"start_time": None, "detected": False},  # ì•ŒëŒ ì—†ìŒ
    "SleepyDriving": {"start_time": None, "detected": False},
    "Yawn": {"start_time": None, "detected": False},
    "Calling": {"start_time": None, "detected": False},
    "Drinking": {"start_time": None, "detected": False},
}

@app.route('/')
def index():
    return render_template('index.html')

def detect_objects(session, frame, class_names, color):
    """ ONNX ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ ê°ì§€ ë° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° """
    input_size = (640, 640)
    height, width, _ = frame.shape  # ì›ë³¸ ì˜ìƒ í¬ê¸°
    scale_x = width / input_size[0]  # ê°€ë¡œ ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨
    scale_y = height / input_size[1]  # ì„¸ë¡œ ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨

    # YOLO ONNX ì…ë ¥ ì „ì²˜ë¦¬
    image_resized = cv2.resize(frame, input_size)
    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)
    image_input = image_rgb.transpose(2, 0, 1)  # (H, W, C) -> (C, H, W)
    image_input = image_input[np.newaxis, :, :, :].astype(np.float32) / 255.0

    # ëª¨ë¸ ì‹¤í–‰
    outputs = session.run(None, {"images": image_input})
    detections = outputs[0][0]  # (1, N, 6) â†’ (N, 6)

    detected_classes = []
    bounding_boxes = []  # ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸

    for det in detections:
        x1, y1, x2, y2, confidence, class_id = det[:6]

        # ì¢Œí‘œë¥¼ ì›ë³¸ í”„ë ˆì„ í¬ê¸°ì— ë§ê²Œ ë³€í™˜
        x1 = int(x1 * scale_x)
        y1 = int(y1 * scale_y)
        x2 = int(x2 * scale_x)
        y2 = int(y2 * scale_y)

        if confidence > 0.3 and 0 <= class_id < len(class_names):  # ì‹ ë¢°ë„ í•„í„°ë§ ë° í´ë˜ìŠ¤ ë²”ìœ„ ì²´í¬
            class_name = class_names[int(class_id)]
            detected_classes.append(class_name)
            bounding_boxes.append((x1, y1, x2, y2, class_name, confidence))

    return detected_classes, bounding_boxes

def process_alerts(detected_classes):
    """ ê°ì§€ëœ í–‰ë™ì— ë”°ë¼ ê²½ê³  ì•ŒëŒ ì¬ìƒ (SafeDriving ì œì™¸) """
    current_time = time.time()

    for class_name in state_flags:
        if class_name == "SafeDriving":  # âœ… SafeDrivingì€ ë¬´ì‹œ
            continue  

        state = state_flags[class_name]

        if class_name in detected_classes:  # âœ… ê°ì§€ë¨
            if not state["detected"]:  # ì²˜ìŒ ê°ì§€ëœ ê²½ìš°
                state["start_time"] = current_time
                state["detected"] = True
            else:
                # SleepyDrivingì€ 2ì´ˆ í›„, ë‚˜ë¨¸ì§€ëŠ” 4ì´ˆ í›„ ì•ŒëŒ
                required_time = 2 if class_name == "SleepyDriving" else 4
                
                if state["start_time"] is not None and current_time - state["start_time"] >= required_time:
                    if class_name in alarms and alarms[class_name].get_num_channels() == 0:  # âœ… KeyError ë°©ì§€
                        alarms[class_name].play()
                        state["start_time"] = current_time  # âœ… ì•ŒëŒ ì¬ìƒ í›„ ì‹œê°„ ë¦¬ì…‹

        else:  # âœ… ê°ì§€ê°€ ì•ˆ ë˜ë©´ ìƒíƒœ ì´ˆê¸°í™”
            if state["detected"]:  # âœ… ê¸°ì¡´ì— ê°ì§€ë˜ì—ˆë‹¤ê°€ ì‚¬ë¼ì§„ ê²½ìš°ì—ë§Œ ìƒíƒœ ì´ˆê¸°í™”
                state["start_time"] = None
                state["detected"] = False

def gen_frames():
    """ ì›¹ìº ì—ì„œ ì‹¤ì‹œê°„ ì˜ìƒ ë°›ì•„ì˜¤ê¸° & YOLO ONNX ì¶”ë¡  """
    cap = cv2.VideoCapture(0)  # ì›¹ìº  í™œì„±í™”
    # cap.set(cv2.CAP_PROP_FPS, 30)  # FPS ì œí•œ

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # ë‘ ë²ˆì§¸ ëª¨ë¸ (Calling, Drinking) ë¨¼ì € ì‹¤í–‰
        detected_classes_2, bounding_boxes_2 = detect_objects(session_2, frame, class_names_2, (0, 0, 255))

        if detected_classes_2:  # Calling, Drinkingì´ ê°ì§€ë˜ë©´ ë‹¤ë¥¸ ê°ì§€ ì°¨ë‹¨
            detected_classes = detected_classes_2
            bounding_boxes = bounding_boxes_2
        else:
            # Calling, Drinkingì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì‹¤í–‰
            detected_classes_1, bounding_boxes_1 = detect_objects(session_1, frame, class_names_1, (0, 255, 0))
            detected_classes = detected_classes_1
            bounding_boxes = bounding_boxes_1  

        # ê°ì§€ëœ ê°ì²´ì— ë”°ë¥¸ ì•ŒëŒ ì²˜ë¦¬
        process_alerts(detected_classes)

        # ê°ì§€ëœ ë°ì´í„° í™•ì¸ (í„°ë¯¸ë„ ì¶œë ¥)
        print(f"ğŸ“Œ ê°ì§€ëœ í–‰ë™: {detected_classes}")

        # ê°ì§€ëœ í–‰ë™ì„ ì›¹ìœ¼ë¡œ ì „ì†¡
        socketio.emit("detected_actions", {"actions": detected_classes})

        # ë°”ìš´ë”© ë°•ìŠ¤ & ë¼ë²¨ í‘œì‹œ (í•´ë‹¹ ëª¨ë¸ì˜ ê°ì§€ë§Œ)
        for x1, y1, x2, y2, class_name, confidence in bounding_boxes:
            color = (0, 0, 255) if class_name in class_names_2 else (0, 255, 0)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, f"{class_name} ({confidence:.2f})", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

        # ì›¹ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ í”„ë ˆì„ ë³€í™˜
        _, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/video_feed')
def video_feed():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=8000, debug=False)
